{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet Classification Using Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Neccessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing, model_selection\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset from CSV (exoTrain.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\User1\\\\Desktop\\\\Exoplanet stars classifier\\\\exoTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      1    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      1   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      1   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      1 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Converting Data into Numpy Arrays ( For Sake of Convenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(df.drop(['LABEL'],1))\n",
    "y_train = np.array(df['LABEL'], dtype ='float')\n",
    "y_train.shape = (len(y_train),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Scaling Data for Better Modelling (Only x values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f_train = preprocessing.scale(x_train)\n",
    "y_f_train = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Using DNN Model for Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(200,activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(300,activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(2,activation = tf.nn.softmax))\n",
    "\n",
    "\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "       loss = 'sparse_categorical_crossentropy',\n",
    "       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Fitting Data into Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5087/5087 [==============================] - 1s 200us/sample - loss: 0.0822 - acc: 0.9872\n",
      "Epoch 2/30\n",
      "5087/5087 [==============================] - 1s 201us/sample - loss: 0.0496 - acc: 0.9927\n",
      "Epoch 3/30\n",
      "5087/5087 [==============================] - 1s 202us/sample - loss: 0.0424 - acc: 0.9927\n",
      "Epoch 4/30\n",
      "5087/5087 [==============================] - 1s 177us/sample - loss: 0.0421 - acc: 0.9925s - loss: 0.070\n",
      "Epoch 5/30\n",
      "5087/5087 [==============================] - 1s 167us/sample - loss: 0.0360 - acc: 0.9931\n",
      "Epoch 6/30\n",
      "5087/5087 [==============================] - 1s 184us/sample - loss: 0.0345 - acc: 0.9935\n",
      "Epoch 7/30\n",
      "5087/5087 [==============================] - 1s 163us/sample - loss: 0.0346 - acc: 0.9937s - loss: 0.0340 - acc: 0\n",
      "Epoch 8/30\n",
      "5087/5087 [==============================] - 1s 183us/sample - loss: 0.0319 - acc: 0.9941\n",
      "Epoch 9/30\n",
      "5087/5087 [==============================] - 1s 179us/sample - loss: 0.0314 - acc: 0.9941s - loss: 0.0309 - acc: 0.99\n",
      "Epoch 10/30\n",
      "5087/5087 [==============================] - 1s 178us/sample - loss: 0.0283 - acc: 0.9949\n",
      "Epoch 11/30\n",
      "5087/5087 [==============================] - 1s 182us/sample - loss: 0.0308 - acc: 0.9941s - loss: 0.036\n",
      "Epoch 12/30\n",
      "5087/5087 [==============================] - 1s 178us/sample - loss: 0.0287 - acc: 0.9949\n",
      "Epoch 13/30\n",
      "5087/5087 [==============================] - 1s 170us/sample - loss: 0.0262 - acc: 0.9955s - loss: 0.0279 - acc: 0\n",
      "Epoch 14/30\n",
      "5087/5087 [==============================] - 1s 176us/sample - loss: 0.0236 - acc: 0.9957s - loss: 0.0297 - acc:\n",
      "Epoch 15/30\n",
      "5087/5087 [==============================] - 1s 186us/sample - loss: 0.0273 - acc: 0.9955s - loss: 0.0311 - a\n",
      "Epoch 16/30\n",
      "5087/5087 [==============================] - 1s 177us/sample - loss: 0.0224 - acc: 0.9961\n",
      "Epoch 17/30\n",
      "5087/5087 [==============================] - 1s 182us/sample - loss: 0.0259 - acc: 0.9957\n",
      "Epoch 18/30\n",
      "5087/5087 [==============================] - 2s 487us/sample - loss: 0.0250 - acc: 0.9955\n",
      "Epoch 19/30\n",
      "5087/5087 [==============================] - 1s 184us/sample - loss: 0.0252 - acc: 0.9959s - loss: 0.0266 - acc:\n",
      "Epoch 20/30\n",
      "5087/5087 [==============================] - 1s 174us/sample - loss: 0.0235 - acc: 0.9965\n",
      "Epoch 21/30\n",
      "5087/5087 [==============================] - 1s 180us/sample - loss: 0.0225 - acc: 0.9965s - loss: 0.0199 - acc:\n",
      "Epoch 22/30\n",
      "5087/5087 [==============================] - 1s 175us/sample - loss: 0.0238 - acc: 0.9955\n",
      "Epoch 23/30\n",
      "5087/5087 [==============================] - 1s 172us/sample - loss: 0.0216 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "5087/5087 [==============================] - 1s 179us/sample - loss: 0.0222 - acc: 0.9965s - loss: 0.05\n",
      "Epoch 25/30\n",
      "5087/5087 [==============================] - ETA: 0s - loss: 0.0201 - acc: 0.996 - 1s 175us/sample - loss: 0.0203 - acc: 0.9963\n",
      "Epoch 26/30\n",
      "5087/5087 [==============================] - 1s 172us/sample - loss: 0.0193 - acc: 0.9959\n",
      "Epoch 27/30\n",
      "5087/5087 [==============================] - 1s 186us/sample - loss: 0.0224 - acc: 0.9961\n",
      "Epoch 28/30\n",
      "5087/5087 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.9949- ETA: 0s - loss: 0.0250 - acc: 0. - 1s 177us/sample - loss: 0.0222 - acc: 0.9951\n",
      "Epoch 29/30\n",
      "5087/5087 [==============================] - 1s 170us/sample - loss: 0.0184 - acc: 0.9957\n",
      "Epoch 30/30\n",
      "5087/5087 [==============================] - 1s 175us/sample - loss: 0.0183 - acc: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x274625aa940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_f_train ,y_f_train , epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Testing Dataset (from exoTest.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:\\\\Users\\\\User1\\\\Desktop\\\\Exoplanet stars classifier\\\\exoTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      1   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      1  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      1   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      1  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      1   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63  ...      14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44  ...    -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27  ...      17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53  ...     122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04  ...     -37.87     -61.85     -27.15     -21.18   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Converting Data into Numpy Arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(df2.drop(['LABEL'],1))\n",
    "y_test = np.array(df2['LABEL'], dtype ='float')\n",
    "y_test.shape = (len(y_test),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Scaling Data for Better Modelling (Only x values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f_test = preprocessing.scale(x_test)\n",
    "y_f_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Checking Trained Data For Overfitting and Underfitting over tested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 156us/sample - loss: 0.3017 - acc: 0.9877\n",
      "Loss % = 30.174284523777793 , Accuracy % = 98.77192974090576 \n"
     ]
    }
   ],
   "source": [
    "val_loss,val_acc = model.evaluate(x_f_test,y_f_test)\n",
    "print(\"Loss % = {} , Accuracy % = {} \".format(val_loss*100,val_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Predicting Star Type of Test Data from Trained Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1,0] -> Normal star   \n",
    "# [0,1] -> Exoplanet star system\n",
    "\n",
    "arr = np.array([[1,0],[0,1]])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________\n",
      "_____________________________________________________\n",
      "Predicted No of Normal Stars  = 568\n",
      "Predicted NO. of Exoplanet stars = 2\n",
      "Total tested stars = 570\n",
      "_____________________________________________________\n",
      "Original No of Normal Stars  = 565\n",
      "Original No. of Exoplanet stars = 5\n",
      "Total tested stars = 570\n",
      "_____________________________________________________\n",
      "Accuracy = 98.77192974090576%\n"
     ]
    }
   ],
   "source": [
    "z = np.round(model.predict(x_f_test))\n",
    "\n",
    "print('_____________________________________________________')\n",
    "#print(\"Prediction : P-Class : O-Class \")\n",
    "\n",
    "c1=c2=c3=c4=0\n",
    "\n",
    "for i in range(0,len(z)):\n",
    "    if np.array_equal(z[i],arr[0]):\n",
    "        #print(\"{} : {} : {}\".format(z[i],0,y_test[i]))\n",
    "        c1+=1\n",
    "    else:\n",
    "        #print(\"{} : {} : {}\".format(z[i],1,y_test[i]))\n",
    "        c2+=1        \n",
    "\n",
    "\n",
    "print('_____________________________________________________')\n",
    "print(\"Predicted No of Normal Stars  = {}\".format(c1))\n",
    "print(\"Predicted NO. of Exoplanet stars = {}\".format(c2))\n",
    "print(\"Total tested stars = {}\".format(len(z)))\n",
    "\n",
    "m = y_f_test\n",
    "\n",
    "print('_____________________________________________________')\n",
    "\n",
    "for i in range(0,len(m)):\n",
    "    if m[i] == 0:\n",
    "        c3+=1\n",
    "    else :\n",
    "        c4+=1 \n",
    "   \n",
    "\n",
    "print(\"Original No of Normal Stars  = {}\".format(c3))\n",
    "print(\"Original No. of Exoplanet stars = {}\".format(c4))\n",
    "print(\"Total tested stars = {}\".format(len(y_f_test)))\n",
    "\n",
    "print('_____________________________________________________')\n",
    "print('Accuracy = {}%'.format((val_acc)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Trained data in a pickle for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = np.hstack((x_f_train,y_f_train))    # Merging the label column (y_test) with the X_test  i.e the total training set\n",
    "\n",
    "with open(\"exoplanet_model.pickle\",\"wb\") as f:\n",
    "    pickle.dump( data , f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
